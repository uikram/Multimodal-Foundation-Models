{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP + LoRA Experiments\n",
    "## Parameter-Efficient Fine-Tuning\n",
    "\n",
    "This notebook demonstrates training and evaluating CLIP with LoRA adapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from models.clip_lora import CLIPLoRA\n",
    "from utils.config import CLIPLoRAConfig\n",
    "from utils.helpers import seed_everything\n",
    "from evaluation.metrics import MetricsTracker\n",
    "from training.trainer_lora import CLIPLoRATrainer\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "seed_everything(42)\n",
    "\n",
    "# Load configuration\n",
    "config = CLIPLoRAConfig(\n",
    "    model_id=\"openai/clip-vit-base-patch32\",\n",
    "    batch_size=32,\n",
    "    num_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    lora_r=16,\n",
    "    lora_alpha=32,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Device: {config.device}\")\n",
    "print(f\"Model: {config.model_id}\")\n",
    "print(f\"LoRA Rank: {config.lora_r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CLIP + LoRA\n",
    "model = CLIPLoRA(config)\n",
    "\n",
    "# Print trainable parameters\n",
    "param_counts = model.count_parameters()\n",
    "print(f\"\\nTotal Parameters: {param_counts['total']:,}\")\n",
    "print(f\"Trainable Parameters: {param_counts['trainable']:,}\")\n",
    "print(f\"Trainable Ratio: {param_counts['trainable']/param_counts['total']*100:.2f}%\")\n",
    "\n",
    "# Initialize metrics tracker\n",
    "metrics = MetricsTracker(\"CLIP_LORA_NOTEBOOK\", config.results_dir)\n",
    "metrics.track_parameters(model)\n",
    "\n",
    "print(\"\\n✓ Model initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = CLIPLoRATrainer(model, config, metrics)\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\\n\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add evaluation code for fine-tuned model\n",
    "# Compare performance before/after fine-tuning\n",
    "\n",
    "print(\"Evaluation code to be implemented...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: LoRA Adapter Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize LoRA adapter weight distributions\n",
    "lora_weights = []\n",
    "\n",
    "for name, param in model.model.named_parameters():\n",
    "    if 'lora' in name and param.requires_grad:\n",
    "        lora_weights.append(param.detach().cpu().numpy().flatten())\n",
    "\n",
    "if lora_weights:\n",
    "    fig, axes = plt.subplots(1, len(lora_weights[:4]), figsize=(16, 4))\n",
    "    \n",
    "    for idx, (ax, weights) in enumerate(zip(axes, lora_weights[:4])):\n",
    "        ax.hist(weights, bins=50, alpha=0.7)\n",
    "        ax.set_title(f'LoRA Layer {idx+1}')\n",
    "        ax.set_xlabel('Weight Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../plots/lora_weight_distributions.png', dpi=300)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No LoRA weights found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics.save_metrics(run_id=\"notebook_experiment\")\n",
    "metrics.print_summary()\n",
    "\n",
    "print(\"\\n✓ Results saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
