{
    "inference_peak_gpu_mb": 777.34912109375,
    "inference_current_gpu_mb": 625.8486328125
}