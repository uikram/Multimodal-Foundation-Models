{
    "inference_peak_gpu_mb": 433.70703125,
    "inference_current_gpu_mb": 344.73779296875
}