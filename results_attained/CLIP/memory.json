{
    "inference_peak_gpu_mb": 429.95703125,
    "inference_current_gpu_mb": 340.98779296875
}