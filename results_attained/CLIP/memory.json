{
    "inference_peak_gpu_mb": 962.474609375,
    "inference_current_gpu_mb": 658.9736328125
}